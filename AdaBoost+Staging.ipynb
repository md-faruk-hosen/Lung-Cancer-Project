{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AsWX1SpFGLE",
        "outputId": "e6fc171c-bcd4-49d0-a450-cdd71630f157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, matthews_corrcoef,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix\n",
        ")\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/Bashar_Staging/TCGA LUAD staging merged_data_I_II.csv\")"
      ],
      "metadata": {
        "id": "hSv56HZrGXHZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter binary classes: Stage I and Stage III\n",
        "data_binary = data[data['Stage'].isin(['Stage I', 'Stage III'])]\n",
        "\n",
        "# Split features and target\n",
        "X = data_binary.drop(columns=['Stage'])\n",
        "y = data_binary['Stage']\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)  # Stage I -> 0, Stage III -> 1\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.24, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply SMOTE to handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# Display resampled distribution\n",
        "resampled_counts = pd.Series(y_resampled).value_counts()\n",
        "resampled_labels = [le.inverse_transform([i])[0] for i in resampled_counts.index]\n",
        "print(\"Resampled class distribution:\")\n",
        "for label, count in zip(resampled_labels, resampled_counts):\n",
        "    print(f\"{label}: {count}\")\n",
        "print()\n",
        "\n",
        "# Train AdaBoost Classifier with optimized parameters\n",
        "model = AdaBoostClassifier(n_estimators=150, learning_rate=0.8, random_state=42)\n",
        "model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_proba = model.predict_proba(X_test_scaled)[:, 1]  # Probability for class 1\n",
        "\n",
        "# Metrics\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_proba)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "# Confusion Matrix and Specificity\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "# Print all metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(f\"\\nAccuracy: {acc:.4f}\")\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "print(f\"MCC: {mcc:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall/Sensitivity: {recall:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf3LkTcRGZ4R",
        "outputId": "cfa815db-e428-4481-96a7-ce517d0b4e4c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampled class distribution:\n",
            "Stage I: 353\n",
            "Stage III: 353\n",
            "\n",
            "Confusion Matrix:\n",
            "[[105   7]\n",
            " [ 20   3]]\n",
            "\n",
            "Accuracy: 0.8000\n",
            "AUC: 0.5396\n",
            "MCC: 0.0975\n",
            "Precision: 0.3000\n",
            "Recall/Sensitivity: 0.1304\n",
            "Specificity: 0.9375\n",
            "F1 Score: 0.1818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y9GRkQsTG7UV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}